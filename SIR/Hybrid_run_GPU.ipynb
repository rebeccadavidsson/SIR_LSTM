{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.nn.LSTMmodel import LSTM\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from SIR_ODE import SIR\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "from numpy import array\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import covsirphy as cs\n",
    "import requests, io, json, urllib\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from itertools import cycle\n",
    "import os.path\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import cycle\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download datasets\n",
    "data_loader = cs.DataLoader(\"input\")\n",
    "jhu_data = data_loader.jhu()\n",
    "population_data = data_loader.population()\n",
    "oxcgrt_data = data_loader.oxcgrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_periods(nums):\n",
    "    nums = sorted(set(nums))\n",
    "    gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s+1 < e]\n",
    "    edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])\n",
    "    return list(zip(edges, edges))\n",
    "    \n",
    "\n",
    "def plot_param(df, periods, TARGET):\n",
    "    fig = px.line(df, x=\"Date\", y=TARGET, title='Lockdown periods in ' + COUNTRY)\n",
    "    for dates in periods:\n",
    "        fig.add_vrect(x0=NPI_df.iloc[dates[0]][\"Date\"], x1=NPI_df.iloc[dates[1]][\"Date\"], line_width=0, fillcolor=\"red\", opacity=0.2)\n",
    "    fig.show()\n",
    "\n",
    "def add_bias(results, BIAS, isBias=True):\n",
    "    data = results.copy()\n",
    "    preds = []\n",
    "    SIR_data = []\n",
    "    dates = []\n",
    "    x_dates, x_preds, total_dates = [], [], []\n",
    "    x_plot_preds = []\n",
    "    \n",
    "    # START Adding bias after days_delay\n",
    "    BIAS_START = DELAY_START + datetime.timedelta(days_delay)\n",
    "    for date, pred, index in zip(data[\"valData\"][\"Date\"], data[\"pred\"], range(0, len(data[\"valData\"]))):\n",
    "        if date >= BIAS_START:\n",
    "            preds.append(pred)\n",
    "            dates.append(date)\n",
    "            SIR_data.append(SIR_results[\"I\"][index])\n",
    "        x_dates.append(date)\n",
    "        x_preds.append(pred)\n",
    "        total_dates.append(date)\n",
    "     # Add bias to prediction\n",
    "    # Calculate trend in SIR-predictions\n",
    "    x = np.arange(0,len(SIR_data))\n",
    "    y = np.array(SIR_data)\n",
    "    if len(y) > 1:\n",
    "        z = np.polyfit(x, y, 1)[0]\n",
    "    else:\n",
    "        z = 1\n",
    "        \n",
    "#     plt.plot(x_dates, x_preds)\n",
    "#     plt.plot(data[\"valData\"][\"Date\"], data[\"valData\"][\"ConfirmedCases\"])\n",
    "#     plt.axvline(BIAS_START, color=\"black\", linestyle=\"dashed\")\n",
    "    \n",
    "    new_preds, old_preds = [], []\n",
    "    weight = 3\n",
    "    for i in range(len(preds)):\n",
    "        if i == len(preds) - 1:\n",
    "            diff = preds[i] - preds[i-1]\n",
    "        else:\n",
    "            diff = preds[i + 1] - preds[i]\n",
    "        percent = (i+1) / days_delay\n",
    "        weight += 0.1\n",
    "        if isBias:\n",
    "            new_trend = (percent * z/weight + diff)\n",
    "            new_trend = new_trend + diff\n",
    "            new_preds.append(preds[i] + new_trend)\n",
    "        else:\n",
    "            new_preds.append(preds[i])\n",
    "        old_preds.append(preds[i])\n",
    "#     plt.plot(dates, new_preds)\n",
    "#     plt.show()\n",
    "    if len(y) <= 1:\n",
    "        new_preds = data[\"pred\"]\n",
    "    combined_new_preds = new_preds\n",
    "#     plt.plot(combined_new_preds)\n",
    "#     plt.show()\n",
    "    # Add data to results\n",
    "    data[\"total_old_pred\"] = data[\"pred\"]\n",
    "    data[\"pred\"] = combined_new_preds\n",
    "    data[\"oldpred\"] = old_preds\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"Stringency_index\"\n",
    "TARGET_NPI = TARGET\n",
    "COUNTRY = \"United Kingdom\"\n",
    "\n",
    "NPI_df = oxcgrt_data.cleaned()\n",
    "NPI_df = NPI_df[NPI_df[\"Country\"] == COUNTRY]\n",
    "\n",
    "# Get lockdown dates\n",
    "NPI_df = NPI_df.reset_index().drop('index', axis=1)\n",
    "NPI_df = NPI_df.groupby(\"Date\").mean().reset_index()\n",
    "\n",
    "# fig = px.line(NPI_df, x=\"Date\", y=TARGET, title='Periods in ' + COUNTRY)\n",
    "# for dates in periods:\n",
    "#     fig.add_vrect(x0=NPI_df.iloc[dates[0]][\"Date\"], x1=NPI_df.iloc[dates[1]][\"Date\"], line_width=0, fillcolor=\"red\", opacity=0.2)\n",
    "# fig.show()\n",
    "\n",
    "s = cs.Scenario(jhu_data, population_data, country=COUNTRY)\n",
    "days_delay, df_periods = s.estimate_delay(oxcgrt_data)\n",
    "print(f'Delay days: {days_delay}')\n",
    "\n",
    "NPI = TARGET_NPI\n",
    "NPI_dates = {}\n",
    "lockdown_indexes = NPI_df[NPI_df[NPI] >= 75].index\n",
    "lockdown_dates = NPI_df[NPI_df[NPI] >= 75][\"Date\"]\n",
    "periods = get_periods(lockdown_indexes)\n",
    "\n",
    "if periods == []:\n",
    "    lockdown_indexes = NPI_df[NPI_df[NPI] >= 65].index\n",
    "    lockdown_dates = NPI_df[NPI_df[NPI] >= 65][\"Date\"]\n",
    "    periods = get_periods(lockdown_indexes)\n",
    "\n",
    "if periods == []:\n",
    "    lockdown_indexes = NPI_df[NPI_df[NPI] >= 4].index\n",
    "    lockdown_dates = NPI_df[NPI_df[NPI] >= 4][\"Date\"]\n",
    "    periods = get_periods(lockdown_indexes)\n",
    "\n",
    "if periods == []:\n",
    "    lockdown_indexes = NPI_df[NPI_df[NPI] >= 3].index\n",
    "    lockdown_dates = NPI_df[NPI_df[NPI] >= 3][\"Date\"]\n",
    "    periods = get_periods(lockdown_indexes)\n",
    "\n",
    "lockdown_dates_adjusted = []\n",
    "for date in lockdown_dates:\n",
    "    new_date = date + datetime.timedelta(days = days_delay)\n",
    "    lockdown_dates_adjusted.append(new_date)\n",
    "NPI_dates[NPI] = lockdown_dates_adjusted\n",
    "\n",
    "lockdown_dates_adjusted = []\n",
    "for date in lockdown_dates:\n",
    "    new_date = date + datetime.timedelta(days = days_delay)\n",
    "    lockdown_dates_adjusted.append(new_date)\n",
    "lockdown_dates_adjusted = pd.Series(lockdown_dates_adjusted) \n",
    "\n",
    "# Save variable DELAY_START, which is equal to the start of a lockdown period\n",
    "# in this case, we will hardcode the script to the second lockdown date\n",
    "# if len(periods) > 2:\n",
    "DELAY_START = NPI_df.iloc[periods[len(periods) - 1][0]].Date\n",
    "# else:\n",
    "#     DELAY_START = NPI_df.iloc[periods[0][0]].Date\n",
    "\n",
    "df = jhu_data.cleaned()\n",
    "df = df[(df[\"Country\"] == COUNTRY) & (df[\"Province\"] == \"-\")]\n",
    "df[\"New Confirmed\"] = df[\"Confirmed\"].diff()\n",
    "\n",
    "if COUNTRY == \"United Kingdom\":\n",
    "    df_params = pd.read_pickle(\"df_United_Kingdom\")\n",
    "else:\n",
    "    df_params = pd.read_pickle(\"../figures/pickles/df_9_countries\")\n",
    "df_params[\"Country\"].unique()\n",
    "df_params = df_params[df_params[\"Country\"] == COUNTRY]\n",
    "# plot_param(df_params, periods, TARGET=\"rho\")\n",
    "\n",
    "# DELAY_START = pd.to_datetime('2020-11-06')\n",
    "TRAIN_UP_TO  = DELAY_START \n",
    "print(DELAY_START)\n",
    "\n",
    "\n",
    "country_df = jhu_data.cleaned()\n",
    "country_df = country_df[(country_df[\"Country\"] == COUNTRY) & (country_df[\"Province\"] == \"-\") ]\n",
    "selection = country_df[country_df[\"Date\"] == DELAY_START + datetime.timedelta(days_delay + 2)]\n",
    "\n",
    "selection[\"Confirmed\"] = abs(selection[\"Confirmed\"].values[0] - selection[\"Confirmed\"].values[0])\n",
    "population_df = population_data.cleaned()\n",
    "N = population_df[population_df[\"Country\"] == COUNTRY][\"Population\"].values[0]\n",
    "selection.head()\n",
    "\n",
    "target_column = \"Confirmed\"\n",
    "if selection[\"Confirmed\"].values[0] == 0:\n",
    "    target_column = \"Infected\"\n",
    "\n",
    "country_df = jhu_data.cleaned()\n",
    "country_df = country_df[(country_df[\"Country\"] == COUNTRY) & (country_df[\"Province\"] == \"-\") ]\n",
    "selection = country_df[country_df[\"Date\"] == DELAY_START + datetime.timedelta(days_delay + 2)]\n",
    "\n",
    "def calc_param(df, lockdown_dates):\n",
    "    total_params = [\"theta\", \"kappa\", \"rho\", \"sigma\"]\n",
    "    calc_params_df = {}\n",
    "    for param in total_params:\n",
    "        values = []\n",
    "        for date in df[\"Date\"].values:\n",
    "            if date in lockdown_dates.values:\n",
    "                values.append(np.mean(df[df['Date'] == date][param]))\n",
    "        calc_params_df[param] = np.mean(values)\n",
    "    return calc_params_df\n",
    "\n",
    "# params = calc_param(df_params, lockdown_dates_adjusted)\n",
    "params_total = {}\n",
    "sir_params_total = {}\n",
    "for p in NPI_dates:\n",
    "    res = calc_param(df_params, pd.Series(NPI_dates[p]))\n",
    "    if not math.isnan(res[\"kappa\"]):\n",
    "        params_total[p] = res\n",
    "\n",
    "        sir = SIR(N=N, I0=selection[target_column].values[0], R0=selection[\"Recovered\"].values[0], \n",
    "                  beta=res[\"rho\"], gamma=res[\"theta\"],\n",
    "                 days=85)\n",
    "        SIR_results = sir.simulate(target=\"Infected\")\n",
    "        sir_params_total[p] = SIR_results\n",
    "\n",
    "# -------------------------- LSTM -------------------------#\n",
    "DEVICE       = 'cpu'\n",
    "ThreshConf   = 70\n",
    "ThreshDead   = 20\n",
    "TARGET       = \"New Confirmed\"\n",
    "TYPE         = \"LSTMCell\"\n",
    "FUTURE_DAYS  = 5\n",
    "RUNS         = 5\n",
    "ERROR_THRESH = 1\n",
    "#     days_delay   = 16\n",
    "if TARGET_NPI != \"Stringency_index\":\n",
    "    bias_bools   = [True]\n",
    "else:\n",
    "    bias_bools = [True, False]\n",
    "\n",
    "BIAS = sir_params_total[TARGET_NPI]\n",
    "\n",
    "for WITH_BIAS in bias_bools:\n",
    "    fname = f\"bias_res_{TARGET_NPI}_{WITH_BIAS}_{COUNTRY}.p\"\n",
    "    print(fname)\n",
    "    results_df = pd.DataFrame(columns=[\"Date\"])\n",
    "\n",
    "    # Check if dataframe already exists to build up on\n",
    "    if os.path.isfile(fname):\n",
    "        results_df = pickle.load(open( fname, \"rb\" ))\n",
    "        j = len(results_df.columns)\n",
    "        RUNS = j + RUNS\n",
    "    else:\n",
    "        j = 0\n",
    "\n",
    "    while j < RUNS:\n",
    "        print(\"RUN\", j)\n",
    "        FUTURE_DAYS  = 5\n",
    "        lstm = LSTM(COUNTRY, TRAIN_UP_TO, FUTURE_DAYS, ThreshDead, TARGET, TYPE, DELAY_START)\n",
    "        results1 = lstm.simulate(ThreshConf=70)\n",
    "        bias_results = add_bias(results1, BIAS)\n",
    "\n",
    "\n",
    "        for i in range(4):\n",
    "            FUTURE_DAYS += 6\n",
    "            lstm = LSTM(COUNTRY, TRAIN_UP_TO, FUTURE_DAYS, ThreshDead, TARGET, TYPE, DELAY_START)\n",
    "            results2 = lstm.simulate(ThreshConf=70, input_data=bias_results)\n",
    "            bias_results = add_bias(results2, BIAS, isBias=WITH_BIAS)\n",
    "\n",
    "        trainData = pd.DataFrame(results2[\"trainData\"])\n",
    "        new_col = pd.DataFrame(trainData)\n",
    "        new_col = new_col.set_index(\"Date\")\n",
    "\n",
    "        if j == 0:\n",
    "            valDates = pd.Series(results2[\"valData\"][\"Date\"])\n",
    "            trainDates = pd.Series(results2[\"trainData\"][\"Date\"])\n",
    "            new_dates = trainDates.append(valDates)\n",
    "            results_df[\"Date\"] = new_dates\n",
    "            results_df = results_df.set_index(\"Date\")\n",
    "            trueCases = results1[\"trainData\"].set_index(\"Date\")\n",
    "            valCases = results1[\"valData\"].set_index(\"Date\")\n",
    "            results_df[\"TrueCases\"] = trueCases[\"ConfirmedCases\"]\n",
    "            results_df[\"valCases\"] = valCases[\"ConfirmedCases\"]\n",
    "\n",
    "        error = results2[\"error\"]\n",
    "\n",
    "        # Don't save run if there were errors in prediction\n",
    "        if error > ERROR_THRESH:\n",
    "            print(error)\n",
    "            RUNS += 1\n",
    "        else:\n",
    "            if j == 0:\n",
    "                results_df[\"ConfirmedCases\"] = new_col[\"ConfirmedCases\"]\n",
    "            else:\n",
    "                new_col = new_col.rename(columns={\"ConfirmedCases\": \"Cases\" + str(j)})\n",
    "                results_df = pd.concat([results_df, new_col[\"Cases\" + str(j)]], axis=1)\n",
    "        j += 1\n",
    "\n",
    "        if WITH_BIAS:\n",
    "            results_df.to_pickle(fname)\n",
    "        else:\n",
    "            results_df.to_pickle(fname)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
