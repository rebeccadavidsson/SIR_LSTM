{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Predictings using LSTM RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to compare outcomes of deep learning methods to mathematical SIR model variants.\n",
    "\n",
    "Deep learning methods require a lot of data as input for training. However, training one single model for all countries across the world raises a lot of problems. Not all countries show the same trend in infections, testing and registration is different for multiple countries, data shows a lot of fluctuations etc. \n",
    "\n",
    "A solution to this problem is to train a model countries' data with similar trends. Training a country is therefore done by using similar countries as training input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import statistics\n",
    "\n",
    "import numpy   as np \n",
    "import pandas  as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics       import mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tqdm             import tqdm\n",
    "from IPython.display  import display \n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data      import compare_countries as cc\n",
    "from core.data      import utils             as dataUtils\n",
    "\n",
    "from core.nn        import WeightInitializer\n",
    "from core.nn.loss   import rmsle_error, l1_norm_error\n",
    "from core.nn.loss   import GradientSmoothLoss\n",
    "\n",
    "from core.networks  import BasicRecurrentPredictor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduceble results\n",
    "torch.manual_seed(123);\n",
    "torch.cuda.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEVICE       = 'cpu'\n",
    "TRAIN_UP_TO  = pd.to_datetime('2020-10-01')\n",
    "RNNNOCELLS = 2\n",
    "# LEARNING_RATE = 0.05\n",
    "CELLTYPE = \"LSTMCell\"\n",
    "ITERATE = 5\n",
    "WINDOWSIZE = 5\n",
    "FUTURESTEPS = 123\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is collected from the [GitHub](https://github.com/CSSEGISandData/COVID-19) repository  created by Johns Hopkins CSSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State Country_Region       Date  ConfirmedCases  Fatalities\n",
       "0            NaN    Afghanistan 2020-01-22             0.0         0.0\n",
       "1            NaN    Afghanistan 2020-01-23             0.0         0.0\n",
       "2            NaN    Afghanistan 2020-01-24             0.0         0.0\n",
       "3            NaN    Afghanistan 2020-01-25             0.0         0.0\n",
       "4            NaN    Afghanistan 2020-01-26             0.0         0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTRY = \"Netherlands\"\n",
    "allData = pd.read_csv('./assets/covid_spread.csv', parse_dates=['Date'])\n",
    "allData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>New Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Province_State Country_Region       Date  ConfirmedCases  Fatalities  \\\n",
       "0 1    Afghanistan    Afghanistan 2020-01-23             0.0         0.0   \n",
       "  2    Afghanistan    Afghanistan 2020-01-24             0.0         0.0   \n",
       "  3    Afghanistan    Afghanistan 2020-01-25             0.0         0.0   \n",
       "  4    Afghanistan    Afghanistan 2020-01-26             0.0         0.0   \n",
       "  5    Afghanistan    Afghanistan 2020-01-27             0.0         0.0   \n",
       "\n",
       "     New Confirmed  \n",
       "0 1            0.0  \n",
       "  2            0.0  \n",
       "  3            0.0  \n",
       "  4            0.0  \n",
       "  5            0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add data to Province_State\n",
    "if COUNTRY is \"global\":\n",
    "    print(\"Converting\")\n",
    "    allData[\"Province_State\"] = \"-\"\n",
    "    allData[\"Country_Region\"] = \"global\"\n",
    "    allData = dataUtils.preprocess_data(allData)\n",
    "    \n",
    "    # Replace Confirmed cases with new confirmed cases\n",
    "    allData = allData.sort_values(\"Date\")\n",
    "    allData = allData.rename(columns={\"Confirmed\": \"ConfirmedCases\", \"Fatal\": \"Fatalities\"})\n",
    "    \n",
    "    allData = allData.reset_index()[columns]\n",
    "    allData[\"New Confirmed\"] = allData.groupby(\"Country_Region\")[\"ConfirmedCases\"].diff()\n",
    "    columns = allData.columns\n",
    "    allData = allData.groupby('Country_Region', as_index=False).apply(lambda group: group.iloc[1:])\n",
    "else:\n",
    "    # Add data to Province_State\n",
    "    allData = dataUtils.preprocess_data(allData)\n",
    "    \n",
    "    allData = allData.sort_values(\"Date\")\n",
    "    allData[\"New Confirmed\"] = allData.groupby(\"Country_Region\")[\"ConfirmedCases\"].diff()\n",
    "    columns = allData.columns\n",
    "    allData = allData.groupby('Country_Region', as_index=False).apply(lambda group: group.iloc[1:])\n",
    "allData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar country training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the data using a threshold. This threshold only selects countries higher than this value. Then, the smallest error is computed by the sliding-window method for every step. Data from the selected country is slided across, to compute the error at each step.  \n",
    "\n",
    "The result is a dataframe containing the following:\n",
    "- **Province_State** : the name of the state/province\n",
    "- **deathError**     : the minimum error that was found between source and that specific country for fatalities\n",
    "- **deathIdx**       : the index where the above error was found (in the thresholded array)\n",
    "- **confirmedError** : the minimum error that was found between source and that specific country for confirmed cases\n",
    "- **confirmedIdx**   : the index where the above error was found (in the thresholded array)\n",
    "\n",
    "**MAPE** (mean absolute percenta error) it used as the comparing measure. This represents the error in percentage relative to the source country, hence being easier to interpret and understand.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>deathError</th>\n",
       "      <th>confirmedError</th>\n",
       "      <th>deathIdx</th>\n",
       "      <th>confirmedIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Japan</td>\n",
       "      <td>0.779142</td>\n",
       "      <td>0.436392</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iran</td>\n",
       "      <td>0.442889</td>\n",
       "      <td>0.467222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>0.690287</td>\n",
       "      <td>0.530056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>0.659473</td>\n",
       "      <td>0.553949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hubei</td>\n",
       "      <td>0.228588</td>\n",
       "      <td>0.571953</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  deathError  confirmedError deathIdx confirmedIdx\n",
       "5          Japan    0.779142        0.436392        2           14\n",
       "3           Iran    0.442889        0.467222        0            0\n",
       "4          Italy    0.690287        0.530056        0            0\n",
       "2         France    0.659473        0.553949        0            0\n",
       "1          Hubei    0.228588        0.571953        1            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>deathError</th>\n",
       "      <th>confirmedError</th>\n",
       "      <th>deathIdx</th>\n",
       "      <th>confirmedIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hubei</td>\n",
       "      <td>0.228588</td>\n",
       "      <td>0.571953</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iran</td>\n",
       "      <td>0.442889</td>\n",
       "      <td>0.467222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spain</td>\n",
       "      <td>0.646557</td>\n",
       "      <td>0.640611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>0.659473</td>\n",
       "      <td>0.553949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>0.690287</td>\n",
       "      <td>0.530056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  deathError  confirmedError deathIdx confirmedIdx\n",
       "1          Hubei    0.228588        0.571953        1            0\n",
       "3           Iran    0.442889        0.467222        0            0\n",
       "7          Spain    0.646557        0.640611        0            0\n",
       "2         France    0.659473        0.553949        0            0\n",
       "4          Italy    0.690287        0.530056        0            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errorData  = cc.get_nearest_sequence(allData, COUNTRY, \n",
    "                                     alignThreshConf = 80,\n",
    "                                     alignThreshDead = 20,  \n",
    "                                     errorFunc       = rmsle_error\n",
    "                                    )\n",
    "\n",
    "display(errorData.sort_values(by='confirmedError').head())\n",
    "display(errorData.sort_values(by='deathError').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>deathError</th>\n",
       "      <th>confirmedError</th>\n",
       "      <th>deathIdx</th>\n",
       "      <th>confirmedIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Henan</td>\n",
       "      <td>2.407042</td>\n",
       "      <td>1.939461</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hubei</td>\n",
       "      <td>0.228588</td>\n",
       "      <td>0.571953</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>0.659473</td>\n",
       "      <td>0.553949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iran</td>\n",
       "      <td>0.442889</td>\n",
       "      <td>0.467222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>0.690287</td>\n",
       "      <td>0.530056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Japan</td>\n",
       "      <td>0.779142</td>\n",
       "      <td>0.436392</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Korea, South</td>\n",
       "      <td>1.215604</td>\n",
       "      <td>0.818127</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spain</td>\n",
       "      <td>0.646557</td>\n",
       "      <td>0.640611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US</td>\n",
       "      <td>1.305151</td>\n",
       "      <td>1.556039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0.766020</td>\n",
       "      <td>0.579083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Province_State  deathError  confirmedError deathIdx confirmedIdx\n",
       "0           Henan    2.407042        1.939461       15            2\n",
       "1           Hubei    0.228588        0.571953        1            0\n",
       "2          France    0.659473        0.553949        0            0\n",
       "3            Iran    0.442889        0.467222        0            0\n",
       "4           Italy    0.690287        0.530056        0            0\n",
       "5           Japan    0.779142        0.436392        2           14\n",
       "6    Korea, South    1.215604        0.818127       13           13\n",
       "7           Spain    0.646557        0.640611        0            0\n",
       "8              US    1.305151        1.556039        0            0\n",
       "9  United Kingdom    0.766020        0.579083        0            0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating traning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data is selected including only the countries that have an average error smaller that a threshold. This is done for both confirmed cases and fatalities. These models are trained seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(87, 56211)</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(87, 56212)</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(87, 56213)</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(87, 56214)</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>Japan</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(87, 56215)</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>Japan</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date Province_State  ConfirmedCases\n",
       "(87, 56211) 2020-01-23          Japan             2.0\n",
       "(87, 56212) 2020-01-24          Japan             2.0\n",
       "(87, 56213) 2020-01-25          Japan             2.0\n",
       "(87, 56214) 2020-01-26          Japan             4.0\n",
       "(87, 56215) 2020-01-27          Japan             4.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confData = dataUtils.get_target_data(allData, errorData, \n",
    "                                     errorThresh = 0.5, \n",
    "                                     country     = COUNTRY, \n",
    "                                     target      = 'confirmed')\n",
    "deadData = dataUtils.get_target_data(allData, errorData, \n",
    "                                     errorThresh = .5, \n",
    "                                     country     = COUNTRY, \n",
    "                                     target      = 'fatalities')\n",
    "\n",
    "confData = confData[[\"Date\", \"Province_State\", \"ConfirmedCases\"]]\n",
    "deadData = deadData[[\"Date\", \"Province_State\", \"Fatalities\"]]\n",
    "\n",
    "confData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) is used to scale the dates because a small standard deviation is expected for features. This scaler will be further used for scaling both the training data and the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "confScaler = dataUtils.get_scaler(confData, 'confirmed')\n",
    "deadScaler = dataUtils.get_scaler(deadData, 'fatalities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reccurent predictor is composed from 2 parts:\n",
    "- reccurent cells  \n",
    "- multi layer perceptron that is applied after each encoded timpestamp \n",
    "Each part will be individually configured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two individual models are trained for the two features, Confirmed Cases and Fatalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the model is shown in this figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN_Flow](../assets/images/rnn_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These define overall shapes of the data and the size of the embeddings:\n",
    "- **chNo**   : the number of input and output features, they must have the same length, in out case this       \n",
    "- **future** : the number of timestapms to predict into the feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **rnnCell** : RNN cell types that are supported in Pytorch (LSTM/GRU/RNN), the most powerfull one is LSTM, though, having a small amount of data(like in our case) GRU may be better choice thus is generalize better. RNNCell is also an option yet, but it yielded the worst results\n",
    "- **rnnNoCells** : represent the number of reccurent cells in the model a higher number leads to a very unstable model (especially for this task) and the exploding gradients problem occurs very often during training \n",
    "- **hidChNo** : number of RNN cell hidden dimension\n",
    "\n",
    "**Note**: yes, this part could have been implemented using the higher level and more optimized [API](https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM) from PyTorch, but I think this is more expressive and easier to understand and it is not such does not require a lot more code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **mlpLayerCfg** : a list with the numbers of neurons in each hidden layer. The layers might be wideer but is to be avoided having a very deep network (numerical instability during training and no real benefit from it)\n",
    "- **mlpActiv** : activation layer after each dense/linear layer, I have used [PReLU](https://pytorch.org/docs/stable/nn.html#prelu) which is a sort of learnable loss \n",
    "- **dropRate** : dropout rate applied after each dense/linear layer, for our case 0 is used\n",
    "- **normType** : normalization layer, not used used\n",
    "- **mlpActivLast** : last layer activation function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the both Confirmed and Fatalities are going to follow the same lead and only a few parameters will vary, I will only explain once everything and add a few notes if that will be necessarly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = WeightInitializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section we have more data, since the cases have started earlier and the fatalities came later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Confirmed Cases Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "confModel = BasicRecurrentPredictor(\n",
    "            # parameters\n",
    "            chNo        = 1,          # number of input features\n",
    "            future      = 0,\n",
    "            returnFullSeq = True,     # return both the encoded sequence \n",
    "                                      # and the future prediction\n",
    "    \n",
    "            # RNN\n",
    "            rnnCell     = CELLTYPE, # RNN cell type (LSTM/GRU/RNN)\n",
    "            rnnNoCells  = RNNNOCELLS,          # no of RNN cells\n",
    "            hidChNo     = 12,         # number of RNN cell hidden dimension\n",
    "            \n",
    "            # MLP\n",
    "            mlpLayerCfg   = [4],      # layer hidden dims\n",
    "            mlpActiv      = 'PReLU',  # inner activation of the mlp\n",
    "            dropRate      = None,     # dropout rate for each layer of mlp\n",
    "            normType      = None,     # normalization type\n",
    "            mlpActivLast  = None      # note that every timestamp \n",
    "                                      # in the sequence will be activated too\n",
    "            \n",
    "            ).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, the model will have the weights initialized as as follows:\n",
    "- RNN : default (provided by PyTorch)\n",
    "- MLP : normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.init_weights(confModel, 'normal_', {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timing constants and data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data_model](../assets/images/data_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants:\n",
    "- **winSize**     - the  size of observation period and prediction period \n",
    "- **obsSize**     - number of timestemps used for observation\n",
    "- **futureSteps** - the number of predicted days, not including the observation period\n",
    "- **supPredSteps** - are the number predicted days that are going to be optimized in a supervised manner\n",
    "- **uPredSteps** - are the number predicted days that are going to be optimized in an unsupervised manner\n",
    "- **allPredSteps** - the total length of the prediction output including the observation period and the future steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize       = WINDOWSIZE\n",
    "obsSize       = 4\n",
    "futureSteps   = FUTURESTEPS\n",
    "supPredSteps  = winSize - obsSize\n",
    "uPredSteps    = futureSteps - supPredSteps\n",
    "allPredSteps  = futureSteps + obsSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataframe from the previously selected data into batches and normalize it. The data is only selected until a specific date, and the rest is left for validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([682, 5, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confTrainData = dataUtils.get_train_data(confData, 'confirmed', \n",
    "                                  step       = 1,\n",
    "                                  winSize    = winSize, \n",
    "                                  trainLimit = TRAIN_UP_TO, \n",
    "                                  scaler     = confScaler,\n",
    "                                  shuffle    = True)\n",
    "confTrainData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathcal{L}_{total} = \\mathcal{L}_{sup} + \\mathcal{L}_{unsup} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supervised loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SmoothL1Loss](https://pytorch.org/docs/stable/nn.html#torch.nn.SmoothL1Loss) (Huber Loss) is used for training. It is less sensitive to outliers than MSELoss and prevents exploding gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "confLoss  = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unsupervised loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may not be very straight forward from data that the output should somehow resemble a logistic curve, so do this we are trying to optimize this in an unsupervised manner. A smoothing loss, is implied which will limit the growth of a function over a large periods. \n",
    "\n",
    "To better scale this loss and to make it more stable, insead of scaling the final result I chose clipping the values before averaging them. \n",
    "\n",
    "Please note that the the length of the predicton and the clipping values are considered hyperparameters, and they should be tuned for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradsTrain  = confTrainData[:, 1:] - confTrainData[:, :-1] \n",
    "confGradMax = gradsTrain.max()\n",
    "\n",
    "confGLoss   = GradientSmoothLoss(confGradMax, uPredSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As optimization algorithm the LBFGS one is chosed, it is a very memory expensive algorithm, but since we have such little data, it works just fine. For more details about how it works I leave the following link on [Quora](https://www.quora.com/Is-the-L-bfgs-always-better-than-stochastic-gradient-descent?share=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confOptim = optim.Adam(confModel.parameters(), \n",
    "#                         lr             = 0.05, \n",
    "#                       )\n",
    "\n",
    "confOptim = optim.LBFGS(confModel.parameters(), \n",
    "                        lr             = 0.05, \n",
    "                        max_iter       = 75, \n",
    "                        tolerance_grad = 1e-7, \n",
    "                        history_size   = 75\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "confModel.to(DEVICE);\n",
    "confTrainData = confTrainData.to(DEVICE);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closure is the function that is passed to the optimizers. Here is the \"bussines logic\" of the training process. For the first OBS_SIZE steps, the models prediction is based on the input data, from there, it uses it's own prediction. The whole sequence is returned and evaluted for optimization. \n",
    "\n",
    "For better stability, after the loss is computed, the gradients are clipped such that their L2 norm is 1. For more details check this [article](https://machinelearningmastery.com/exploding-gradients-in-neural-networks/) by Jason Brownlee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](../assets/images/model_data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_closure():\n",
    "    confOptim.zero_grad()\n",
    "    confModel.returnFullSeq = True\n",
    "    \n",
    "    # slice data\n",
    "    obsData = confTrainData[:,:obsSize]\n",
    "    \n",
    "    # make prediction\n",
    "    out  = confModel(obsData, future = futureSteps)\n",
    "    out  = out.reshape(-1, allPredSteps, 1)\n",
    "    \n",
    "    # compute gradients\n",
    "    loss = confLoss(out[:, :winSize], confTrainData)\n",
    "    \n",
    "    # unsupervised loss\n",
    "    smoothLoss = confGLoss(out[:,winSize:], 0.25)\n",
    "    loss += smoothLoss \n",
    "    \n",
    "    # make prediciton follow an ascending trend\n",
    "    # by forcing the gradients to be positie (still testing)\n",
    "    grads = out[:, 1:] - out[:, :-1]\n",
    "    grads[grads > 0] = 0\n",
    "    grads = grads.mean().abs()\n",
    "    loss += grads\n",
    "    loss.backward()\n",
    "    \n",
    "    # clip gradients / numerical stability\n",
    "    nn.utils.clip_grad_norm_(confModel.parameters(), 1.0)\n",
    "      \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop is the section where the parameters are optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:29<?, ?it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-7a935a26bcf2>\", line 3, in <module>\n",
      "    loss = confOptim.step(conf_closure)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/torch/optim/lbfgs.py\", line 437, in step\n",
      "    loss = float(closure())\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"<ipython-input-26-ce16e6e9037f>\", line 9, in conf_closure\n",
      "    out  = confModel(obsData, future = futureSteps)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/rebecca/Desktop/SIR_LSTM/LSTM/core/networks/basic_recurrent_predictor.py\", line 137, in forward\n",
      "    hidState[i], cellState[i] = r(inp, (hidState[i], cellState[i]))\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 955, in forward\n",
      "    self.bias_ih, self.bias_hh,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "pBar = tqdm(range(ITERATE))\n",
    "for i in pBar:\n",
    "    loss = confOptim.step(conf_closure)\n",
    "    \n",
    "    # update tqdm to show loss and lr\n",
    "    pBar.set_postfix({'Loss ' : loss.item(), \n",
    "                      'Lr'    : confOptim.param_groups[0]['lr']})\n",
    "    \n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError('Loss is NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation process is done for the source country only. For this, the last OBS_SIZE timestemps from the train data are fed into the model, and the output is compared with data from validation period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confValData, confValLabel = dataUtils.get_val_data(confData, 'confirmed', \n",
    "                                                   COUNTRY, \n",
    "                                                   TRAIN_UP_TO, \n",
    "                                                   obsSize, \n",
    "                                                   confScaler)\n",
    "confValData = confValData.to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluating the prediction, MAPE is used. The error is only computed on the predicted future and not on the predicted observation period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "confModel.eval()\n",
    "# get figure\n",
    "fig, ax = plt.subplots(1, 1, figsize = (9, 4))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.suptitle(COUNTRY + ' confirmed cases prediction')\n",
    "\n",
    "# make prediction\n",
    "confModel.returnFullSeq = False\n",
    "pred   = confModel(confValData, future = futureSteps).cpu().detach().numpy()\n",
    "pred   = confScaler.inverse_transform(pred[0])\n",
    "\n",
    "error  = rmsle_error(pred[:confValLabel.shape[0]], confValLabel.numpy())\n",
    "print(\"RMSLE : %2.5f\"% error.item(), ' (not normalized)')             \n",
    "\n",
    "# prediction\n",
    "predDate = pd.date_range(start = TRAIN_UP_TO, periods=pred.shape[0])              \n",
    "sns.lineplot(y = pred, x = predDate, ax = ax, linewidth=4.5)\n",
    "\n",
    "\n",
    "# plot train data\n",
    "showTrainData = confData[confData['Province_State'] == COUNTRY]\n",
    "showTrainData = showTrainData[showTrainData['Date'] < TRAIN_UP_TO]\n",
    "sns.lineplot(y = 'ConfirmedCases', x = 'Date', data = showTrainData, ax = ax, linewidth=4.5)\n",
    "\n",
    "# plot val data\n",
    "showValData = confData[confData['Province_State'] == COUNTRY]\n",
    "showValData = showValData[showValData['Date'] >= TRAIN_UP_TO]\n",
    "sns.lineplot(y = 'ConfirmedCases', x ='Date', data = showValData, ax = ax, linewidth=4.5);\n",
    "\n",
    "# SIR = pd.read_csv('assets/SIR_global.csv', parse_dates=['Date'])\n",
    "# sns.lineplot(x=\"Date\", y=\"Confirmed\", data=SIR, ax = ax, linewidth=4.5)\n",
    "\n",
    "# SIRD = pd.read_csv('assets/SIRD_global.csv', parse_dates=['Date'])\n",
    "# sns.lineplot(x=\"Date\", y=\"Confirmed\", data=SIRD, ax = ax, linewidth=4.5)\n",
    "\n",
    "# SIRF = pd.read_csv('assets/SIRF_global.csv', parse_dates=['Date'])\n",
    "# sns.lineplot(x=\"Date\", y=\"Confirmed\", data=SIRF, ax = ax, linewidth=4.5)\n",
    "\n",
    "\n",
    "# ax.legend(['LSTM', 'GRU', 'True', 'Train', \"SIR\", \"SIRD\", \"SIRF\"])\n",
    "ax.legend(['LSTM', 'True', 'Train'])\n",
    "ax.axvline(x=TRAIN_UP_TO, ymin = 0.0, ymax = 1.0, linestyle='--', lw = 1, color = '#808080')\n",
    "ax.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df1 = pd.DataFrame(pred, index=predDate, columns=[\"RNN\"])\n",
    "# df8 = pd.DataFrame(pred_LSTM, index=predDate, columns=[\"LSTM\"])\n",
    "# df2 = pd.DataFrame(pred_GRU, index=predDate, columns=[\"GRU\"])\n",
    "# df3 = pd.DataFrame(SIRF[\"Fatal\"].values, index=SIRF[\"Date\"].values, columns=[\"SIRF\"])\n",
    "# df4 = pd.DataFrame(SIR[\"Confirmed\"].values, index=SIR[\"Date\"].values, columns=[\"SIR\"])\n",
    "# df5 = pd.DataFrame(SIRD[\"Confirmed\"].values, index=SIRD[\"Date\"].values, columns=[\"SIRD\"])\n",
    "# df6 = pd.DataFrame(showTrainData[\"Fatalities\"].values, index=showTrainData[\"Date\"].values, columns=[\"train\"])\n",
    "# df7 = pd.DataFrame(showValData[\"Fatalities\"].values, index=showValData[\"Date\"].values, columns=[\"val\"])\n",
    "\n",
    "# merged = df1.join(df2)\n",
    "# merged = merged.join(df3)\n",
    "# merged = merged.join(df4)\n",
    "# merged = merged.join(df5)\n",
    "# merged = merged.join(df8)\n",
    "# merged = merged.join(df6, how=\"outer\")\n",
    "# merged = merged.join(df7, how=\"outer\")\n",
    "# merged\n",
    "\n",
    "# # merged2 = df6.merge(df7)\n",
    "# # merged2\n",
    "# merged.to_pickle(\"global_comparison_fatalities.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fatalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because all the explication were done in the previous section, here cleaner view of the code is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "deadModel = BasicRecurrentPredictor(\n",
    "            # basic parameters\n",
    "            chNo          = 1,              # number of input features\n",
    "            future        = 0,\n",
    "            returnFullSeq = True,\n",
    "    \n",
    "            # RNN\n",
    "            rnnCell       = 'LSTMCell',     # RNN cell type (LSTM/GRU/RNN)\n",
    "            rnnNoCells    = 1,              # no of RNN cells\n",
    "            hidChNo       = 16,             # number of RNN cell hidden dimension\n",
    "    \n",
    "            # MLP\n",
    "            mlpLayerCfg   = [4],            # layer hidden dims\n",
    "            mlpActiv      = 'PReLU',        # inner activation of the mlp\n",
    "            dropRate      = None,           # dropout rate for each layer of mlp\n",
    "            normType      = None,           # normalization type\n",
    "            mlpActivLast  = None,           # note that every timestamp in the sequence \n",
    "                                            # will be activated too\n",
    "            ).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize models weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.init_weights(deadModel, 'normal_', {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timming constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deadTrainData = dataUtils.get_train_data(deadData, 'fatalities', \n",
    "                                      step       = 1,\n",
    "                                      winSize    = winSize, \n",
    "                                      trainLimit = TRAIN_UP_TO, \n",
    "                                      scaler     = deadScaler,\n",
    "                                      shuffle    = True)\n",
    "deadTrainData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deadLoss  = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradsTrain = deadTrainData[:, 1:] - deadTrainData[:, :-1] \n",
    "deadGradMax = gradsTrain.max()\n",
    "\n",
    "deadGLoss = GradientSmoothLoss(deadGradMax, uPredSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deadOptim = optim.LBFGS(deadModel.parameters(), \n",
    "                        lr             = 0.05, \n",
    "                        max_iter       = 75, \n",
    "                        tolerance_grad = 1e-7, \n",
    "                        history_size   = 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deadModel.to(DEVICE);\n",
    "deadTrainData = deadTrainData.to(DEVICE);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dead_closure():\n",
    "    deadOptim.zero_grad()\n",
    "    \n",
    "    # slice data\n",
    "    obsData  = deadTrainData[:,:obsSize]\n",
    "\n",
    "    out  = deadModel(obsData, future = futureSteps)\n",
    "    out  = out.reshape(-1, allPredSteps, 1)\n",
    " \n",
    "    # compute and backprop loss\n",
    "    loss = deadLoss(out[:, :winSize], deadTrainData)   \n",
    "    \n",
    "    # smooth\n",
    "    smoothLoss = deadGLoss(out[:,winSize:], 0.25)\n",
    "    loss += smoothLoss\n",
    "    \n",
    "    # make prediciton follow an ascending trend\n",
    "    # (still testing)\n",
    "    grads = out[:, 1:] - out[:, :-1]\n",
    "    grads[grads > 0] = 0\n",
    "    grads = grads.mean().abs()\n",
    "    loss += grads\n",
    "    loss.backward()\n",
    "    \n",
    "    # clip gradient for numerical stability\n",
    "    nn.utils.clip_grad_norm_(deadModel.parameters(), 1.0)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pBar = tqdm(range(10))\n",
    "for i in pBar:\n",
    "    loss = deadOptim.step(dead_closure)\n",
    "    pBar.set_postfix({'Loss ' : loss.item()})\n",
    "    \n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError('Loss is NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deadValData, deadValLabel = dataUtils.get_val_data(deadData, 'fatalities', \n",
    "                                                   COUNTRY, \n",
    "                                                   TRAIN_UP_TO, \n",
    "                                                   obsSize, \n",
    "                                                   deadScaler)\n",
    "deadValData = deadValData.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deadModel.eval()\n",
    "\n",
    "# get figure\n",
    "fig, ax = plt.subplots(1, 1, figsize = (9, 4))\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.suptitle(COUNTRY + ' fatalities prediction')\n",
    "\n",
    "# make prediction\n",
    "deadModel.returnFullSeq = False\n",
    "pred   = deadModel(deadValData, future = futureSteps).cpu().detach().numpy()\n",
    "pred   = deadScaler.inverse_transform(pred[0])\n",
    "error  = rmsle_error(pred[:deadValLabel.shape[0]], deadValLabel.numpy())\n",
    "print('RMSLE: ', error)             \n",
    "\n",
    "# plot prediction\n",
    "predDate = pd.date_range(start = TRAIN_UP_TO, periods=pred.shape[0])              \n",
    "sns.lineplot(y = pred, x = predDate, ax = ax, linewidth=4.5 )\n",
    "\n",
    "# plot train data\n",
    "showTrainData = deadData[deadData['Province_State'] == COUNTRY]\n",
    "showTrainData = showTrainData[showTrainData['Date'] < TRAIN_UP_TO]\n",
    "sns.lineplot(y = 'Fatalities', x = 'Date', data = showTrainData, ax = ax, linewidth=4.5)\n",
    "\n",
    "# plot val data\n",
    "showValData = deadData[deadData['Province_State'] == COUNTRY]\n",
    "showValData = showValData[showValData['Date'] >= TRAIN_UP_TO]\n",
    "sns.lineplot(y = 'Fatalities', x ='Date', data = showValData, ax = ax, linewidth=4.5);\n",
    "\n",
    "ax.legend(['Pred', 'Train', 'Validation'])\n",
    "ax.axvline(x=TRAIN_UP_TO, ymin = 0.0, ymax = 1.0, linestyle='--', lw = 1, color = '#808080')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deadData.to_csv(\"fatalities_train.csv\")\n",
    "# showValData.to_csv(\"fatalities_val.csv\")\n",
    "showValData\n",
    "# # get figure\n",
    "# fig, ax = plt.subplots(1, 1, figsize = (9, 4))\n",
    "# ax.tick_params(axis='x', rotation=45)\n",
    "# fig.suptitle(COUNTRY + ' fatalities prediction')\n",
    "\n",
    "# # make prediction\n",
    "# deadModel.returnFullSeq = False\n",
    "# pred   = deadModel(deadValData, future = futureSteps).cpu().detach().numpy()\n",
    "# pred   = deadScaler.inverse_transform(pred[0])\n",
    "# error  = rmsle_error(pred[:deadValLabel.shape[0]], deadValLabel.numpy())\n",
    "# print('RMSLE: ', error)             \n",
    "\n",
    "# # plot prediction\n",
    "# predDate = pd.date_range(start = TRAIN_UP_TO, periods=pred.shape[0])              \n",
    "# sns.lineplot(y = pred, x = predDate, ax = ax, linewidth=4.5 )\n",
    "\n",
    "# # plot train data\n",
    "# showTrainData = deadData[deadData['Province_State'] == COUNTRY]\n",
    "# showTrainData = showTrainData[showTrainData['Date'] < TRAIN_UP_TO]\n",
    "# sns.lineplot(y = 'Fatalities', x = 'Date', data = showTrainData, ax = ax, linewidth=4.5)\n",
    "\n",
    "# # plot val data\n",
    "# showValData = deadData[deadData['Province_State'] == COUNTRY]\n",
    "# showValData = showValData[showValData['Date'] >= TRAIN_UP_TO]\n",
    "# sns.lineplot(y = 'Fatalities', x ='Date', data = showValData, ax = ax, linewidth=4.5);\n",
    "\n",
    "# SIR = pd.read_csv('assets/SIR_global.csv', parse_dates=['Date'])\n",
    "# SIR[\"Recovered\"] = SIR[\"Recovered\"] / 25\n",
    "# sns.lineplot(x=\"Date\", y=\"Recovered\", data=SIR, ax = ax, linewidth=4.5)\n",
    "\n",
    "# SIRD = pd.read_csv('assets/SIRD_global.csv', parse_dates=['Date'])\n",
    "# SIRD[\"Recovered\"] = SIRD[\"Recovered\"] / 25\n",
    "# sns.lineplot(x=\"Date\", y=\"Recovered\", data=SIRD, ax = ax, linewidth=4.5)\n",
    "\n",
    "# SIRF = pd.read_csv('assets/SIRF_global.csv', parse_dates=['Date'])\n",
    "# SIRF[\"Recovered\"] = SIRF[\"Recovered\"] / 25\n",
    "# sns.lineplot(x=\"Date\", y=\"Recovered\", data=SIRF, ax = ax, linewidth=4.5)\n",
    "\n",
    "# ax.legend(['LSTM', 'True', 'Train', \"SIR\", \"SIRD\", \"SIRF\"])\n",
    "# ax.axvline(x=TRAIN_UP_TO, ymin = 0.0, ymax = 1.0, linestyle='--', lw = 1, color = '#808080')\n",
    "# ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
